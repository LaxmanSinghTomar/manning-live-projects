{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Building and Training Text Classification Model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxboA9GNjJO5"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjftYq4pjJMJ",
        "outputId": "58d1a5cc-5a4e-4220-9c03-0bf67e182d0b"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test)=  tf.keras.datasets.imdb.load_data(\n",
        "    path = 'imdb.npz',\n",
        "    num_words = None,\n",
        "    skip_top = 0,\n",
        "    maxlen = None, \n",
        "    seed = 113,\n",
        "    start_char = 1,\n",
        "    oov_char = 2,\n",
        "    index_from = 3\n",
        ")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qp5Q0liTjJKq"
      },
      "source": [
        "unique, counts=  np.unique(y_train, return_counts=  True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7cWspScjJId",
        "outputId": "9a7fb94f-bc51-4e2d-d54e-1f04fd06d146"
      },
      "source": [
        "print(np.asarray((unique, counts)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[    0     1]\n",
            " [12500 12500]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7D098mYFjP4t"
      },
      "source": [
        "idx = np.argwhere(y_train > 0) # select positive comments index in training data\n",
        "np.random.seed(seed = 100) # yse seed to enure selected records are always same\n",
        "np.random.shuffle(idx) # shuffle at random"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAbad1x8jP2P",
        "outputId": "647149e0-0fce-43bb-d646-8061ec5eff85"
      },
      "source": [
        "idx"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  581],\n",
              "       [  433],\n",
              "       [ 8960],\n",
              "       ...,\n",
              "       [16030],\n",
              "       [13730],\n",
              "       [11208]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ap2mxfPNiRrh",
        "outputId": "c4e62b91-fc96-4056-847f-9f1e75d6c94d"
      },
      "source": [
        "FRAC = 0.25\n",
        "idxs = idx[:round(FRAC*len(idx))]\n",
        "\n",
        "# fractioned positive cases\n",
        "y_trains = y_train[idxs]\n",
        "x_trains = x_train[idxs]\n",
        "\n",
        "print(len(y_trains), len(x_trains))\n",
        "\n",
        "# preserve negative cases\n",
        "idxn = np.argwhere(y_train==0)\n",
        "x_train0 = x_train[idxn]\n",
        "y_train0 = y_train[idxn]\n",
        "\n",
        "print(len(x_train0), len(y_train0))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3125 3125\n",
            "12500 12500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UED2PTHHrAVu",
        "outputId": "3894a4a5-7c78-4b06-ff40-c70ebe1930c7"
      },
      "source": [
        "over_idxs = np.random.choice(idxs.squeeze(), size = 12500, replace=True)\n",
        "\n",
        "# ovesampled positive reviews\n",
        "y_train1 = y_train[over_idxs]\n",
        "x_train1 = x_train[over_idxs] \n",
        "\n",
        "print(len(y_train1), len(x_train1))\n",
        "print(len(x_train0), len(y_train0))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12500 12500\n",
            "12500 12500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WINXHFlRvTXb",
        "outputId": "e83e6b4a-c75e-47a0-d3a8-7c01769412bd"
      },
      "source": [
        "# combining Xs and ys\n",
        "x_train = np.concatenate((x_train0, x_train1), axis = None)\n",
        "y_train = np.concatenate((y_train0, y_train1), axis = None)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print('\\n')\n",
        "print(x_train)\n",
        "print('\\n')\n",
        "print(len(x_train[1]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000,) (25000,)\n",
            "\n",
            "\n",
            "[list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95])\n",
            " list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 44076, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 51428, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113])\n",
            " list([1, 249, 1323, 7, 61, 113, 10, 10, 13, 1637, 14, 20, 56, 33, 2401, 18, 457, 88, 13, 2626, 1400, 45, 3171, 13, 70, 79, 49, 706, 919, 13, 16, 355, 340, 355, 1696, 96, 143, 4, 22, 32, 289, 7, 61, 369, 71, 2359, 5, 13, 16, 131, 2073, 249, 114, 249, 229, 249, 20, 13, 28, 126, 110, 13, 473, 8, 569, 61, 419, 56, 429, 6, 1513, 18, 35, 534, 95, 474, 570, 5, 25, 124, 138, 88, 12, 421, 1543, 52, 725, 6397, 61, 419, 11, 13, 1571, 15, 1543, 20, 11, 4, 22016, 5, 296, 12, 3524, 5, 15, 421, 128, 74, 233, 334, 207, 126, 224, 12, 562, 298, 2167, 1272, 7, 2601, 5, 516, 988, 43, 8, 79, 120, 15, 595, 13, 784, 25, 3171, 18, 165, 170, 143, 19, 14, 5, 7224, 6, 226, 251, 7, 61, 113])\n",
            " ...\n",
            " list([1, 6, 1830, 3073, 11, 11550, 9, 4, 956, 18, 14, 467, 4, 9959, 22, 63, 9, 1220, 163, 441, 5, 2276, 261, 12, 1199, 12646, 11, 678, 22, 7257, 4, 194, 78, 5016, 16, 24, 626, 8, 12417, 7, 2258, 638, 938, 21, 16, 7897, 11, 288, 812, 5, 617, 11, 2258, 75380, 10, 10, 12, 9, 2411, 15, 4, 194, 78, 5016, 115, 69, 4, 4936, 3401, 7, 6, 363, 766, 1069, 89, 111, 76568, 363, 47, 626, 14, 291, 141, 17, 13, 124, 37, 556, 72, 4, 194, 78, 5016, 6, 2070, 52, 1724, 22, 47, 69, 8, 5016, 36598, 23, 94, 205, 10, 10, 2185, 11, 4, 194, 78, 5016, 524, 18512, 15601, 9, 3308, 5, 867, 17, 4232, 4, 18581, 8, 2244, 213, 10400, 1750, 37, 24, 64, 9, 112, 7013, 34, 41, 658, 21, 82, 9, 44, 8, 1585, 41, 292, 5, 630, 56, 656, 6, 15943, 23, 6, 162, 113, 248, 1844, 284, 1808, 43767, 37, 9, 893, 299, 10748, 4, 6359, 4594, 5016, 1750, 37, 271, 4, 1727, 3073, 1615, 8, 339, 27, 1537, 3083, 68, 3564, 5, 2147, 29, 70, 850, 39, 27, 1537, 184, 1279, 6123, 40373, 122, 13, 43, 67, 41, 11, 6, 1982, 2153, 11169, 299, 6087, 4, 20158, 8, 30, 37, 495, 107, 2632, 31, 17, 6, 5700, 3189, 4, 85, 17, 6, 39135, 6409, 41, 109, 1568, 4, 12273, 18, 653, 2923, 4, 3137, 21, 9, 4, 222, 4394, 7, 4, 105, 88, 7, 6, 583, 7, 6, 145, 65, 42, 3666, 17, 8, 138, 59, 127, 51, 59, 127, 6087, 9, 185, 195, 8, 131, 412, 33, 344, 19, 6, 11804, 374, 370, 16356, 1155, 597, 37, 6069, 23, 41, 190, 41, 846, 26, 24, 617, 8, 30, 574, 19, 41, 113, 11, 101, 96, 63, 186, 1032, 225, 57, 3721, 452, 42, 4595, 336, 133, 8, 1260, 138, 6, 1280, 1564, 250, 39, 6, 11550, 14536, 62, 2257, 8, 30, 6, 532, 82630, 5700, 3189, 37, 60885, 765, 18, 39839, 6282, 4807, 10, 10, 466, 14, 13004, 4, 194, 78, 5016, 2880, 11, 1058, 173, 88, 12, 9, 6, 654, 235, 52, 22, 10, 10, 17, 31, 238, 535, 2799, 8, 5016, 9, 4, 5074, 18, 113, 1116, 45, 128, 8, 1783, 11, 19, 199, 2194, 5, 79, 11, 4, 5016, 247, 74, 870, 23, 4, 8225, 88, 113, 571, 8, 25, 553, 10, 10, 4, 194, 78, 5016, 9, 6, 87, 1304, 20, 6, 87, 10711, 20, 6, 87, 51, 774, 13, 110, 20, 5, 349, 40, 12, 17, 73, 17, 372])\n",
            " list([1, 13, 66, 423, 14, 20, 5, 435, 145, 8, 67, 12, 107, 211, 53, 746, 6, 1269, 10, 10, 1563, 14380, 9309, 4, 239, 59, 16, 40, 6, 5396, 1132, 23, 4, 17327, 21219, 19, 41, 5254, 59, 20975, 46, 11, 3980, 5, 4021, 656, 6, 99, 185, 1461, 5, 6668, 3103, 7, 41, 4270, 22891, 3992, 1328, 7, 478, 2714, 8, 4, 1873, 10, 10, 4, 22, 16, 368, 7, 307, 2442, 4, 85497, 4, 389, 6139, 4, 7011, 9237, 367, 4, 24528, 13, 572, 510, 4, 2213, 3888, 707, 5, 4, 32914, 7, 84830, 10, 10, 12, 69, 6, 547, 7, 73165, 7, 10361, 15, 9, 121, 84, 7, 817, 10037, 11, 19920, 861, 1154, 17, 59, 2371, 187, 4, 777, 1603, 11, 4, 4301, 59, 9, 33, 3964, 5, 138, 24, 51, 9, 8, 20879, 6, 2113, 11, 4, 2120, 10, 10, 4, 226, 20, 9, 6, 147, 1694])\n",
            " list([1, 11, 14, 2006, 7, 4, 32996, 5, 62024, 7, 325, 308, 3843, 299, 3434, 14021, 35, 5059, 1412, 8, 8, 70749, 8, 193, 46, 7276, 12191, 37, 9, 399, 49, 3239, 970, 15, 80, 3341, 1113, 18, 4, 1138, 4583, 2217, 7, 4, 37545, 205, 1169, 11, 1577, 8, 14, 14021, 215, 27463, 27, 1214, 2720, 17, 6, 3331, 123, 1325, 6, 1761, 18, 1719, 2549, 20696, 13599, 9803, 5, 6, 16996, 3697, 3944, 6264, 7457, 7230, 10, 10, 33442, 4, 1759, 1409, 10, 10, 4, 116, 34, 4, 293, 105, 33, 222, 16, 52, 17, 16, 8, 30, 873, 49, 7, 308, 12034, 414, 16, 179, 540, 24, 398, 18, 90, 17, 29, 400, 468, 3148, 660, 12, 279, 2270, 9, 53, 1863, 1820, 276, 2589, 6, 87, 5, 400, 642, 239, 7457, 7230, 137, 207, 115, 77, 6, 194, 337, 7, 6142, 16, 53, 74, 4513, 18, 4, 217, 5, 952, 73, 13599, 9803, 190, 16, 184, 394, 36, 887, 35, 1564, 655, 4986, 42, 1766, 42, 845, 15, 1191, 16, 424, 8, 30, 1719, 323, 472, 36, 435, 2241, 18, 342, 19, 41, 10, 10, 40, 13, 301, 752, 4, 487, 468, 6, 117, 3463, 5, 10039, 33, 757, 262, 308, 12034, 414, 24, 76, 7, 12, 330, 21, 49, 4, 65, 82, 188, 6, 227, 2761, 33, 757, 63, 9, 478, 18, 6, 2006, 8, 6, 213, 21, 12, 562, 12, 8, 6, 226, 162, 651, 133, 3466, 4, 33472, 5, 7230, 401, 6, 2375, 646, 4869, 8040, 469, 5, 15, 166, 6, 327, 60, 1493, 7, 4, 10433, 7, 4, 22, 5, 4, 81092, 7, 4, 156, 10, 10, 9475, 24386, 37, 2453, 69, 6, 16575, 7, 147, 898, 8, 27, 403, 122, 6, 478, 292, 19, 6, 247, 1876, 9557, 22, 29, 2400, 4, 392, 158, 1431, 352, 55, 73, 10188, 12, 8, 97, 12, 977, 8, 30, 76, 53, 24386, 82, 1319, 8, 1780, 3890, 4, 1285, 7, 4, 65, 19, 4, 1350, 5, 254, 8, 106, 531, 7, 4, 147, 325, 587, 4682, 7, 8862, 525, 10, 10, 17, 230, 17, 4, 831, 2006, 271, 94, 3694, 168, 23, 4, 64464, 7, 325, 9, 55, 73, 224, 262, 4, 32307, 5061, 55410, 8410, 23, 4, 1206, 590, 9904, 33, 757, 12, 461, 6, 117, 99, 76, 21, 11, 4, 130, 12, 131, 1863, 2235, 51, 45, 170, 18, 35, 6, 185, 86716, 12270, 552, 7, 405, 10, 10, 444, 4, 22, 9, 55, 73, 93, 18, 4, 15274, 352, 5, 45, 407, 1517, 7, 6, 168, 12, 528, 140, 180, 17, 31, 7, 4, 87, 15550, 7, 438, 21, 45, 434, 24, 4, 249, 10, 10, 693, 158])]\n",
            "\n",
            "\n",
            "141\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCWql7gjw_Ub",
        "outputId": "ee9894de-a105-4066-8afc-d3619e2254c7"
      },
      "source": [
        "shuffled_idx = np.arange(0, len(y_train), 1)\n",
        "np.random.seed(seed=300)\n",
        "np.random.shuffle(shuffled_idx)\n",
        "print(shuffled_idx.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CEFY9f-xFw6",
        "outputId": "7a8e42e1-bfbb-464f-98f7-30d527f4b8f0"
      },
      "source": [
        "shuffled_idx"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([14841, 22400, 10026, ...,  5834,  6625, 17617])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jR_H3hiUxHu8",
        "outputId": "a6804b6e-de77-4981-b26d-4037d5677dbf"
      },
      "source": [
        "x_train_shuffled = x_train[shuffled_idx]\n",
        "y_train_shuffled = y_train[shuffled_idx]\n",
        "\n",
        "print(x_train_shuffled.shape, y_train_shuffled.shape)\n",
        "print('\\n')\n",
        "print(x_train_shuffled)\n",
        "print('\\n')\n",
        "print(len(x_train_shuffled[1]))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000,) (25000,)\n",
            "\n",
            "\n",
            "[list([1, 6, 212, 15, 952, 1238, 73, 16, 4, 117, 698, 781, 4, 4313, 7, 761, 1745, 9075, 12, 3734, 4, 86, 8173, 7, 5428, 4745, 5, 15918, 13384, 159, 15, 117, 22, 44, 14362, 1797, 23, 4, 5269, 1117, 631, 39513, 5, 137, 4745, 5, 13384, 26, 24, 572, 73, 3941, 8, 7004, 212, 12, 32, 7900, 367, 1780, 13384, 9, 2814, 6, 185, 255, 37, 630, 56, 11, 37145, 4313, 2408, 12629, 4745, 1455, 10873, 34, 96, 7, 6, 1606, 631, 5382, 11356, 2106, 59, 127, 285, 614, 8, 16038, 90, 21, 11, 4, 932, 96, 108, 140, 29, 734, 18, 41, 5, 59, 734, 18, 90, 21, 6, 622, 420, 7, 4074, 2043, 3453, 54, 51152, 761, 1745, 198, 32, 59, 889, 2402, 11, 6, 854, 9, 197, 34, 4745, 8, 30, 6, 1021, 255, 8, 97, 2294, 433, 5, 53, 1139, 1635, 2691, 3164, 4798, 271, 8, 4745, 1786, 6, 4313, 39, 27, 322, 937, 3214, 2796, 1291, 215, 30, 13384, 50, 9, 49, 327, 985, 7, 4, 10548, 414, 5, 253, 4665, 7, 861, 2420, 25, 70, 67, 15, 4745, 9, 24, 99, 5669, 19, 4, 212, 21, 11, 283, 4745, 240, 6, 11152, 1624, 5, 1545, 5, 29, 5931, 4, 7004, 1299, 5, 505, 279, 24, 19, 3964, 21, 19, 8685, 13384, 16, 57, 87, 9710, 17, 35, 524, 21, 59, 16, 633, 3275, 195, 5, 466, 68, 19951, 125, 268, 3122, 7, 41, 952, 73, 19, 4745, 14, 16, 814, 11, 402, 22875, 15, 272, 55, 5243, 639, 316, 272, 60, 32436, 74, 488, 1881, 21, 382, 4, 2492, 738, 6432, 56])\n",
            " list([1, 316, 9, 345, 1715, 42, 7521, 14, 22, 13, 244, 170, 19, 1715, 12, 9, 38, 73, 324, 5, 38, 73, 917, 307, 14, 22, 9, 18, 84, 37, 1144, 73, 2882, 22, 231, 48, 25, 26, 24, 6, 337, 7, 73, 224, 108, 7, 265, 25, 62, 784, 14, 21, 48, 25, 40, 4, 6014, 7, 116, 1381, 65, 5, 943, 168, 57, 1037, 95, 133])\n",
            " list([1, 261, 3069, 1712, 122, 6, 389, 292, 17, 4049, 13, 421, 15, 4, 22, 286, 4, 118, 13, 69, 110, 33, 4, 130, 7, 4, 20, 13, 16, 317, 547, 40, 50, 16, 142, 1012, 11, 12, 10, 10, 3069, 1712, 122, 6, 404, 292, 151, 5, 59, 93, 72, 784, 41, 5, 2240, 41, 32, 4, 137, 2814, 2234, 122, 55, 52, 17, 4, 29654, 3060, 6104, 5, 13, 38, 33910, 90, 469, 4, 20, 18, 112, 11, 119, 19, 141, 6, 527, 6772, 45, 141, 6, 619, 155, 54, 31, 659, 90, 765, 11, 119, 19, 6, 78, 4449, 5, 262, 48, 45, 294, 40, 67836, 6104, 37, 9, 6, 2728, 415, 151, 1235, 10, 10, 11, 4, 130, 4, 116, 16, 51, 385, 143, 5, 24, 4, 114, 4, 277, 136, 16, 572, 52, 21, 13, 244, 24, 31, 8, 202, 12, 245, 261, 409, 203, 169, 14, 20, 52, 13, 16, 31, 37, 258, 12, 38, 38, 13, 144, 386, 14, 20, 8, 148, 37, 40, 6, 78, 4449, 38, 36, 70, 67, 51, 203, 593, 8, 98, 48, 36, 169, 533, 11, 119, 19, 15, 527, 415])\n",
            " ...\n",
            " list([1, 45, 254, 8, 264, 35, 206, 3015, 3705, 4509, 20, 100, 30, 38, 357, 21, 14, 16, 48525, 1157, 4, 114, 9, 35, 20777, 7, 85, 2579, 1991, 47723, 1554, 4, 1647, 1733, 206, 9, 32, 318, 302, 5, 57, 406, 676, 10, 10, 45, 6, 700, 274, 65, 44, 6, 604, 7, 1165, 406, 1340, 37, 26, 8, 30, 556, 88, 507, 2985, 7393, 31, 7, 68, 612, 4509, 37, 1777, 125, 35, 4767, 1272, 8, 607, 98, 5, 46232, 6, 113, 17, 6, 13747, 10358, 4, 1894, 2179, 32466, 19, 35, 5213, 1722, 489, 114, 8, 193, 120, 4, 182, 5, 4509, 19632, 27, 162, 113, 8, 607, 4, 182, 10, 10, 4, 310, 13, 219, 16, 2278, 5, 15, 203, 28, 21384, 4, 8672, 7, 4, 15581, 1523, 114, 5, 700, 274, 2476, 10105, 318, 302, 21, 13, 1781, 60, 4850, 7626, 149, 709, 291, 6795, 62, 28, 258, 14, 3955, 5, 4086])\n",
            " list([1, 323, 675, 2324, 314, 2553, 314, 2553, 1972, 2710, 314, 8582, 1972, 10, 10, 1538, 1538, 29370, 47, 6, 1676, 501, 47, 69, 712, 19, 5212, 5, 9, 150, 12564, 6, 1392, 6482, 15, 9, 231, 90, 7214, 5, 8148, 8, 4816, 567, 8, 27, 322, 9286, 6909, 6577, 37, 497, 8, 1070, 4, 223, 295, 21, 630, 56, 582, 125, 53, 40, 6, 27980, 2086, 41, 452, 7634, 39025, 8335, 9, 1887, 7, 15286, 492, 1514, 1441, 12510, 2064, 5, 27, 12915, 1392, 6482, 15, 9, 5679, 90, 125, 4, 13115, 4, 22, 1160, 134, 83652, 105, 17, 36, 57418, 367, 19, 68, 456, 10, 10, 12, 9, 301, 15, 4, 698, 306, 8, 358, 112, 4309, 5, 15, 62, 1470, 149, 108, 15, 2836, 98, 14, 96, 108, 40, 24218, 34, 1642, 2468, 14, 45, 6, 787, 7, 6, 1912, 223, 3067, 972, 34, 823, 3460, 9691, 5, 1672, 4, 243, 3379, 5134, 62, 9643, 56, 40, 6, 289, 265, 6979, 12, 9, 82, 2027, 6, 787, 7, 532, 6608, 349, 289, 5122, 972, 5, 257, 13498, 4, 85, 11179, 6, 223, 972, 5, 372, 269, 8, 1070, 12, 295, 466, 24, 112, 565, 195, 48, 25, 1261, 56, 6, 117, 7, 51, 45, 44, 39, 4, 125, 270, 25, 70, 67, 12, 152, 2339, 8, 30, 7771, 829, 39, 4, 380, 5, 12, 434, 152, 4363, 11, 14, 10, 10, 45, 283, 51, 316, 301, 44, 4, 354, 5, 4, 485, 381, 29370, 5, 6577, 81, 1645, 49, 87, 116, 75, 67, 29370, 1585, 12, 19, 27, 322, 3318, 41, 4271, 103, 49, 53, 6804, 9168, 4581, 2244, 180, 315, 6, 1699, 2599, 19, 41, 5, 19228, 6, 801, 19289, 7, 1209, 5, 1148, 715, 54, 59, 3055, 8, 387, 90, 67, 27, 554, 4716, 11, 6, 1955, 561, 75, 67, 6577, 11268, 1585, 41, 19596, 23, 6, 10585, 4, 368, 1488, 7, 4, 314, 159, 4562, 11, 10, 10, 14, 9, 160, 7, 148, 108, 121, 225, 57, 15261, 8, 794, 17, 141, 43, 6, 147, 113, 235, 7, 134, 5034, 456, 2918, 23, 39, 31, 251, 8, 4, 375, 45, 77, 5352, 34, 111, 587, 4, 32825, 21, 12, 66, 16, 43, 99, 2671, 5, 3752, 18, 72, 13, 28, 57, 208, 8, 7100, 12, 18, 14, 1275, 51, 13, 697, 44, 12, 39, 4, 125, 270, 21, 1038, 14, 9, 89, 13, 258, 12])\n",
            " list([1, 225, 57, 96, 8, 6275, 83020, 23640, 39, 6, 7159, 8456, 42, 589, 8, 1634, 12, 772, 715, 5, 5542, 1390, 361, 18, 85, 102, 14, 9, 88, 12, 218, 6, 20, 45, 35, 326, 5, 6, 547, 15, 4, 1057, 28, 15, 820, 188, 679, 83, 35, 3258, 17, 4885, 17, 6, 22, 51, 75, 67, 26, 24, 4, 83166, 7, 6, 114, 21, 247, 6, 720, 7, 687, 15, 75, 92, 67, 11, 108, 175, 251, 21, 64, 838, 1448, 17, 4, 978, 75, 3147, 80, 6281, 54, 75, 842, 44, 49, 1579, 1494, 11, 4, 1636, 7, 42, 39, 369, 75, 75, 67, 9, 263, 1546, 7, 84, 15, 26, 27036, 8, 178, 57, 31, 75, 124, 21, 2002, 14324, 557, 7, 98, 11, 6, 274, 42, 23, 248, 42, 1198, 38, 51, 81, 75, 67, 687, 75, 67, 84, 6545, 1953, 5, 5021, 6518, 64, 4, 1090, 9, 39, 142, 28053, 12, 9, 4, 6770, 904, 5, 5614, 15, 4, 2969, 7, 6, 4707, 47, 1668, 8, 1778, 151, 13854, 42, 406, 876, 270, 11, 522, 4575, 3653, 4305, 263, 1850, 511, 429, 5, 11, 3639, 8, 4, 532, 9879, 27776, 7, 682, 2011, 134, 2373, 26, 2620, 3685, 60580, 15, 70, 2444, 101, 11144, 75, 70, 838, 48, 75, 1762, 261, 4, 1729, 623, 238, 30, 110, 17, 1676, 42, 9123, 4, 105, 26, 24, 533, 2819, 36, 26, 406, 3529, 2987, 6, 994, 8, 6, 1081, 701, 10250, 2011, 15, 9, 724, 4, 14977, 36, 585, 2905, 24, 15, 36, 26, 126, 654, 42, 619, 21, 36, 2715, 6, 552, 7, 532, 79393, 54, 36, 847, 724, 5, 245, 39, 4, 1720, 7, 682, 581, 36, 64, 2715, 283, 113, 11, 4, 1249, 182, 60, 151, 15, 9, 4, 375, 1440, 7, 682, 2011, 33, 4, 130, 58076, 23640, 9, 6, 21077, 7, 40576, 11728, 8, 4, 1249, 182, 17, 60, 4, 91, 9877, 1328, 7, 4, 703, 18034, 8, 263, 9024, 7, 3724, 75, 1585, 263, 3741, 23, 4, 2524, 8, 341, 7, 4, 406, 1103])]\n",
            "\n",
            "\n",
            "68\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDpmTH6NyrHJ",
        "outputId": "d7b8ab99-2270-4462-9e64-858a9d5ca259"
      },
      "source": [
        "word_index = tf.keras.datasets.imdb.get_word_index()\n",
        "\n",
        "word_index = {k:(v+3) for k,v in word_index.items()} \n",
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START>\"] = 1\n",
        "word_index[\"<UNK>\"] = 2  # unknown\n",
        "word_index[\"<UNUSED>\"] = 3\n",
        "\n",
        "index_word = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "def decode_review(encoded_array):\n",
        "    return ' '.join([index_word.get(i, '?') for i in encoded_array])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2i7qGnZExoFA",
        "outputId": "429785da-a89c-4dc5-ee0c-a0a4ab245d8b"
      },
      "source": [
        "train_data = tf.keras.preprocessing.sequence.pad_sequences(x_train_shuffled,\n",
        "                                                        value=word_index[\"<PAD>\"],\n",
        "                                                        padding='pre',\n",
        "                                                        maxlen=256)\n",
        "\n",
        "test_data = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
        "                                                       value=word_index[\"<PAD>\"],\n",
        "                                                       padding='pre',\n",
        "                                                       maxlen=256)\n",
        "\n",
        "print(train_data.shape, test_data.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000, 256) (25000, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_beqr24R1FZG",
        "outputId": "23cf225f-a9f7-40f5-916b-339e448544e4"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    train_data, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20000, 256) (20000,) (5000, 256) (5000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIawa8Rc22hK",
        "outputId": "baa577a0-a9b8-4a7a-bfeb-ec68b3cf7a43"
      },
      "source": [
        "# Shuffle training data for cross validation during training cycle\n",
        "FRAC = 0.8 # fraction of training data used for training. Remaining is for cross validation.\n",
        "idx = np.arange(len(train_data))\n",
        "np.random.seed(seed=400)\n",
        "np.random.shuffle(idx)\n",
        "\n",
        "idxs = idx[:round(len(idx)*FRAC)] # Select random 80% for training data\n",
        "partial_x_train = train_data[idxs]\n",
        "partial_y_train = y_train[idxs]\n",
        "\n",
        "x_val = np.delete(train_data, idxs.tolist(), axis=0) # select remaining as cross validation data\n",
        "y_val = np.delete(y_train, idxs.tolist(), axis=0)\n",
        "\n",
        "print(partial_x_train.shape, partial_y_train.shape)\n",
        "print(x_val.shape, y_val.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20000, 256) (20000,)\n",
            "(5000, 256) (5000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHTrwkSL0QDb"
      },
      "source": [
        "vocab_size = len(word_index)\n",
        "\n",
        "MAX_SENTENCE_LENGTH=256\n",
        "EMBEDDING_SIZE=16\n",
        "HIDDEN_LAYER_SIZE=64\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, 64),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Mw2dHOI0QAj"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVoF8sb60P-4",
        "outputId": "718c6fc0-00ab-4025-c78c-85b0ac797774"
      },
      "source": [
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=40,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    verbose=1)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "40/40 [==============================] - 22s 355ms/step - loss: 0.6933 - accuracy: 0.4968 - val_loss: 0.6935 - val_accuracy: 0.4950\n",
            "Epoch 2/40\n",
            "40/40 [==============================] - 13s 329ms/step - loss: 0.6851 - accuracy: 0.5569 - val_loss: 0.7048 - val_accuracy: 0.5064\n",
            "Epoch 3/40\n",
            "40/40 [==============================] - 13s 329ms/step - loss: 0.6278 - accuracy: 0.6550 - val_loss: 0.7323 - val_accuracy: 0.4894\n",
            "Epoch 4/40\n",
            "40/40 [==============================] - 13s 330ms/step - loss: 0.5503 - accuracy: 0.7276 - val_loss: 0.8167 - val_accuracy: 0.4962\n",
            "Epoch 5/40\n",
            "40/40 [==============================] - 13s 327ms/step - loss: 0.4890 - accuracy: 0.7673 - val_loss: 0.8864 - val_accuracy: 0.4916\n",
            "Epoch 6/40\n",
            "40/40 [==============================] - 13s 327ms/step - loss: 0.4439 - accuracy: 0.7889 - val_loss: 0.9085 - val_accuracy: 0.4916\n",
            "Epoch 7/40\n",
            "40/40 [==============================] - 13s 329ms/step - loss: 0.4158 - accuracy: 0.7976 - val_loss: 0.9797 - val_accuracy: 0.4940\n",
            "Epoch 8/40\n",
            "40/40 [==============================] - 13s 330ms/step - loss: 0.3949 - accuracy: 0.8051 - val_loss: 1.0086 - val_accuracy: 0.4922\n",
            "Epoch 9/40\n",
            "40/40 [==============================] - 13s 330ms/step - loss: 0.3769 - accuracy: 0.8098 - val_loss: 1.0280 - val_accuracy: 0.4964\n",
            "Epoch 10/40\n",
            "40/40 [==============================] - 13s 329ms/step - loss: 0.3619 - accuracy: 0.8153 - val_loss: 0.9940 - val_accuracy: 0.4896\n",
            "Epoch 11/40\n",
            "40/40 [==============================] - 13s 331ms/step - loss: 0.3489 - accuracy: 0.8165 - val_loss: 1.0501 - val_accuracy: 0.4878\n",
            "Epoch 12/40\n",
            "40/40 [==============================] - 13s 328ms/step - loss: 0.3353 - accuracy: 0.8196 - val_loss: 1.0664 - val_accuracy: 0.4898\n",
            "Epoch 13/40\n",
            "40/40 [==============================] - 13s 331ms/step - loss: 0.3264 - accuracy: 0.8227 - val_loss: 1.1618 - val_accuracy: 0.4842\n",
            "Epoch 14/40\n",
            "40/40 [==============================] - 13s 328ms/step - loss: 0.3148 - accuracy: 0.8277 - val_loss: 1.2883 - val_accuracy: 0.4850\n",
            "Epoch 15/40\n",
            "40/40 [==============================] - 13s 329ms/step - loss: 0.3009 - accuracy: 0.8281 - val_loss: 1.1751 - val_accuracy: 0.4874\n",
            "Epoch 16/40\n",
            "40/40 [==============================] - 13s 330ms/step - loss: 0.3018 - accuracy: 0.8326 - val_loss: 1.2677 - val_accuracy: 0.4938\n",
            "Epoch 17/40\n",
            "40/40 [==============================] - 13s 327ms/step - loss: 0.2915 - accuracy: 0.8314 - val_loss: 1.3304 - val_accuracy: 0.4850\n",
            "Epoch 18/40\n",
            "40/40 [==============================] - 13s 327ms/step - loss: 0.2889 - accuracy: 0.8316 - val_loss: 1.3160 - val_accuracy: 0.4910\n",
            "Epoch 19/40\n",
            "40/40 [==============================] - 13s 331ms/step - loss: 0.2840 - accuracy: 0.8342 - val_loss: 1.6482 - val_accuracy: 0.4888\n",
            "Epoch 20/40\n",
            "40/40 [==============================] - 13s 324ms/step - loss: 0.2840 - accuracy: 0.8337 - val_loss: 1.5980 - val_accuracy: 0.4840\n",
            "Epoch 21/40\n",
            "40/40 [==============================] - 13s 328ms/step - loss: 0.2795 - accuracy: 0.8371 - val_loss: 1.6427 - val_accuracy: 0.4838\n",
            "Epoch 22/40\n",
            "40/40 [==============================] - 13s 325ms/step - loss: 0.2779 - accuracy: 0.8382 - val_loss: 1.8795 - val_accuracy: 0.4824\n",
            "Epoch 23/40\n",
            "40/40 [==============================] - 13s 330ms/step - loss: 0.2771 - accuracy: 0.8390 - val_loss: 1.5696 - val_accuracy: 0.4858\n",
            "Epoch 24/40\n",
            "40/40 [==============================] - 13s 328ms/step - loss: 0.2755 - accuracy: 0.8387 - val_loss: 1.6250 - val_accuracy: 0.4860\n",
            "Epoch 25/40\n",
            "40/40 [==============================] - 13s 327ms/step - loss: 0.2738 - accuracy: 0.8416 - val_loss: 2.0427 - val_accuracy: 0.4862\n",
            "Epoch 26/40\n",
            "40/40 [==============================] - 13s 324ms/step - loss: 0.2735 - accuracy: 0.8412 - val_loss: 1.9292 - val_accuracy: 0.4846\n",
            "Epoch 27/40\n",
            "40/40 [==============================] - 13s 326ms/step - loss: 0.2710 - accuracy: 0.8417 - val_loss: 1.6010 - val_accuracy: 0.4844\n",
            "Epoch 28/40\n",
            "40/40 [==============================] - 13s 328ms/step - loss: 0.2700 - accuracy: 0.8438 - val_loss: 1.8798 - val_accuracy: 0.4772\n",
            "Epoch 29/40\n",
            "40/40 [==============================] - 13s 329ms/step - loss: 0.2714 - accuracy: 0.8426 - val_loss: 2.1242 - val_accuracy: 0.4838\n",
            "Epoch 30/40\n",
            "40/40 [==============================] - 13s 326ms/step - loss: 0.2696 - accuracy: 0.8413 - val_loss: 2.0145 - val_accuracy: 0.4808\n",
            "Epoch 31/40\n",
            "40/40 [==============================] - 13s 327ms/step - loss: 0.2687 - accuracy: 0.8437 - val_loss: 1.7887 - val_accuracy: 0.4840\n",
            "Epoch 32/40\n",
            "40/40 [==============================] - 13s 328ms/step - loss: 0.2665 - accuracy: 0.8434 - val_loss: 2.0708 - val_accuracy: 0.4842\n",
            "Epoch 33/40\n",
            "40/40 [==============================] - 13s 326ms/step - loss: 0.2665 - accuracy: 0.8448 - val_loss: 1.8920 - val_accuracy: 0.4848\n",
            "Epoch 34/40\n",
            "40/40 [==============================] - 13s 326ms/step - loss: 0.2673 - accuracy: 0.8457 - val_loss: 2.0227 - val_accuracy: 0.4814\n",
            "Epoch 35/40\n",
            "40/40 [==============================] - 13s 326ms/step - loss: 0.2657 - accuracy: 0.8443 - val_loss: 2.1654 - val_accuracy: 0.4896\n",
            "Epoch 36/40\n",
            "40/40 [==============================] - 13s 326ms/step - loss: 0.2654 - accuracy: 0.8460 - val_loss: 2.0261 - val_accuracy: 0.4808\n",
            "Epoch 37/40\n",
            "40/40 [==============================] - 13s 326ms/step - loss: 0.2658 - accuracy: 0.8470 - val_loss: 2.1323 - val_accuracy: 0.4854\n",
            "Epoch 38/40\n",
            "40/40 [==============================] - 13s 325ms/step - loss: 0.2654 - accuracy: 0.8470 - val_loss: 1.9363 - val_accuracy: 0.4826\n",
            "Epoch 39/40\n",
            "40/40 [==============================] - 13s 329ms/step - loss: 0.2658 - accuracy: 0.8464 - val_loss: 2.4494 - val_accuracy: 0.4854\n",
            "Epoch 40/40\n",
            "40/40 [==============================] - 13s 324ms/step - loss: 0.2657 - accuracy: 0.8436 - val_loss: 2.1384 - val_accuracy: 0.4836\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BhVbDcG19Yn",
        "outputId": "2f1c1657-aa01-462b-a9bd-0ba204f12a17"
      },
      "source": [
        "predicted = model.predict(test_data)\n",
        "predicted"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.6254888 ],\n",
              "       [0.19100961],\n",
              "       [0.5520443 ],\n",
              "       ...,\n",
              "       [0.703851  ],\n",
              "       [0.30264166],\n",
              "       [0.50384945]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "DDvaZOCg_-9u",
        "outputId": "685ecd3e-8611-4715-9382-9557469184e0"
      },
      "source": [
        "predicted[predicted > 0.5] = 1\n",
        "predicted[predicted <= 0.5] = 0\n",
        "predictedf = predicted.flatten().astype(int)\n",
        "\n",
        "import pandas as pd\n",
        "df3 = pd.DataFrame(data=predictedf, columns=['predicted'])\n",
        "refdf = pd.DataFrame(data=y_test, columns=['actual'])\n",
        "\n",
        "y_actu = pd.Series(refdf['actual'], name='ACTUAL')\n",
        "y_pred = pd.Series(df3['predicted'], name='PREDICTED')\n",
        "predicted_results = y_pred.tolist()\n",
        "truth = y_actu.tolist()\n",
        "\n",
        "dl_confusion = pd.crosstab(y_actu, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
        "dl_confusion"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Predicted</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>All</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Actual</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6055</td>\n",
              "      <td>6445</td>\n",
              "      <td>12500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6520</td>\n",
              "      <td>5980</td>\n",
              "      <td>12500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>All</th>\n",
              "      <td>12575</td>\n",
              "      <td>12425</td>\n",
              "      <td>25000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Predicted      0      1    All\n",
              "Actual                        \n",
              "0           6055   6445  12500\n",
              "1           6520   5980  12500\n",
              "All        12575  12425  25000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnI4kxO7AXp6",
        "outputId": "407ea03a-b687-4d66-e412-de8fce63795f"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "report = classification_report(truth, predicted_results)\n",
        "print(report)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.48      0.48     12500\n",
            "           1       0.48      0.48      0.48     12500\n",
            "\n",
            "    accuracy                           0.48     25000\n",
            "   macro avg       0.48      0.48      0.48     25000\n",
            "weighted avg       0.48      0.48      0.48     25000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNbHhbnDCLZz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}